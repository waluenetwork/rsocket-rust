#!/usr/bin/env python3
"""
Channel Streaming Comparison Example
Compares batch vs callback-based channel streaming approaches.
"""

import asyncio
import time
import rsocket_rust

class ChannelCallbackObserver:
    def __init__(self, name):
        self.name = name
        self.responses = []
        self.start_time = time.time()
        self.completed = False
    
    def on_response(self, payload, index):
        current_time = time.time()
        elapsed = (current_time - self.start_time) * 1000
        print(f"  ğŸ“¥ [{self.name}] Response {index} at {elapsed:.1f}ms: {payload.data_utf8()}")
        self.responses.append({'index': index, 'timestamp': current_time})
    
    def on_complete(self, total_responses, success, error):
        current_time = time.time()
        elapsed = (current_time - self.start_time) * 1000
        self.completed = True
        if success:
            print(f"  âœ… [{self.name}] Channel completed at {elapsed:.1f}ms ({total_responses} responses)")
        else:
            print(f"  âŒ [{self.name}] Channel failed at {elapsed:.1f}ms: {error}")

async def test_channel_comparison():
    """Compare batch vs callback channel streaming approaches"""
    print("ğŸ§ª Channel Streaming Approaches Comparison")
    print("=" * 60)
    
    try:
        client = await rsocket_rust.RSocketFactory.connect_tcp(
            rsocket_rust.TcpClientTransport("127.0.0.1:7881")
        )
        print("âœ… Connected to server")
        print()
        
        input_payloads = []
        for i in range(1, 4):
            payload = (rsocket_rust.Payload.builder()
                       .set_data_utf8(f"Comparison test {i}")
                       .build())
            input_payloads.append(payload)
        
        print("ğŸ“¦ Test 1: Batch Channel (current)")
        print("-" * 40)
        
        start_time = time.time()
        responses = await client.request_channel(input_payloads)
        end_time = time.time()
        
        print(f"ğŸ“¥ Sent {len(input_payloads)} inputs, received {len(responses)} responses in batch")
        print(f"â±ï¸  Total time: {(end_time - start_time):.3f} seconds")
        print("ğŸ“‹ All responses received at once (batch processing)")
        print()
        
        print("ğŸ”„ Test 2: Callback Channel (reactive)")
        print("-" * 40)
        
        observer = ChannelCallbackObserver("Callback")
        
        start_time = time.time()
        total_responses = await client.request_channel_with_callback(
            input_payloads, observer.on_response, observer.on_complete
        )
        end_time = time.time()
        
        print(f"ğŸ“¥ Sent {len(input_payloads)} inputs, processed {total_responses} responses via callbacks")
        print(f"â±ï¸  Total time: {(end_time - start_time):.3f} seconds")
        print("ğŸ“‹ Responses processed individually as they arrived")
        
        print("\n" + "=" * 60)
        print("ğŸ“Š CHANNEL ANALYSIS")
        print("=" * 60)
        print("Batch Channel Approach:")
        print("  âœ… Simple to use")
        print("  âŒ All inputs sent at once")
        print("  âŒ All responses collected before processing")
        print("  âŒ No backpressure control")
        print("  âŒ Memory usage grows with channel size")
        print()
        print("Callback Channel Approach:")
        print("  âœ… True reactive bidirectional streaming")
        print("  âœ… Responses processed as they arrive")
        print("  âœ… Constant memory usage")
        print("  âœ… Supports backpressure")
        print("  âœ… Observable timing between responses")
        print("  âœ… Completion callbacks (on_complete event)")
        print(f"  âœ… Channel completion detected: {observer.completed}")
            
    except Exception as e:
        print(f"âŒ Comparison error: {e}")

async def main():
    await asyncio.sleep(2)
    await test_channel_comparison()

if __name__ == "__main__":
    asyncio.run(main())
